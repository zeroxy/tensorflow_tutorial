{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto(gpu_options = tf.GPUOptions(allow_growth=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ones_1:0\", shape=(2, 2), dtype=float32)\n",
      "[[ 1.  1.]\n",
      " [ 1.  1.]]\n",
      "[ 2.  2.]\n",
      "[[ 1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config = sess_config)\n",
    "\n",
    "a = tf.ones((2,2))\n",
    "b = tf.reduce_sum(a, axis=1)\n",
    "c = tf.reshape(a, (1,4))\n",
    "\n",
    "print(a)\n",
    "print(sess.run(a))\n",
    "print(sess.run(b))\n",
    "print(sess.run(c))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.]\n",
      " [ 1.  1.]]\n",
      "[ 2.  2.]\n",
      "[[ 2.  2.]\n",
      " [ 2.  2.]]\n",
      "(1, 2)  =  (2, 2)\n",
      "[[ 2.  2.]\n",
      " [ 2.  2.]]\n",
      "[[ 4.  4.]]\n"
     ]
    }
   ],
   "source": [
    "bb = tf.constant([[2,2]], dtype=tf.float32)\n",
    "with tf.Session(config = sess_config) as sess:\n",
    "    print(sess.run(a))\n",
    "    print(sess.run(b))\n",
    "    print(sess.run(b*a))\n",
    "    print(bb.shape, \" = \" ,  a.shape)\n",
    "    print(sess.run(bb*a))\n",
    "    print(sess.run(tf.matmul(bb,a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01221879 -0.04479288]\n",
      " [-0.09659357 -0.02552533]\n",
      " [ 0.06752612 -0.07375654]\n",
      " [ 0.06802593 -0.03256749]\n",
      " [-0.05811738 -0.1637394 ]]\n",
      "[[3 2 3]\n",
      " [1 2 3]]\n",
      "Tensor(\"Variable/read:0\", shape=(5, 2), dtype=float32)\n",
      "Tensor(\"Variable_1/read:0\", shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.Variable(tf.random_normal([5,2], stddev=0.1))\n",
    "w2 = tf.Variable([[3,2,3],[1,2,3]])\n",
    "\n",
    "with tf.Session(config = sess_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    w1_fetch, w2_fetch = sess.run([w1,w2])\n",
    "    print(w1_fetch)\n",
    "    print(w2_fetch)\n",
    "    print(w1)\n",
    "    print(w2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init :  0\n",
      "update 0 :  1\n",
      "update 1 :  2\n",
      "update 2 :  3\n"
     ]
    }
   ],
   "source": [
    "state = tf.Variable(0, name = \"counter\")\n",
    "update = tf.assign(state, tf.add(state, tf.constant(1)))\n",
    "\n",
    "with tf.Session(config = sess_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"init : \", sess.run(state))\n",
    "    for i in range(3):\n",
    "        sess.run(update)\n",
    "        print(\"update {} : \".format(i), sess.run(state))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19563007  0.42904913]\n",
      " [ 0.76093233  0.82296515]]\n",
      "[[ 0.25382924  0.18190956]\n",
      " [ 0.80656767  0.97068322]]\n",
      "[[ 0.39571378  0.45205778]\n",
      " [ 0.85692394  0.93725932]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.placeholder(tf.float32, [2,2])\n",
    "matrix2 = tf.placeholder(shape=[2,2], dtype=tf.float32)\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    mv1 = sess.run(tf.random_uniform(shape=[2,2], dtype=tf.float32))\n",
    "    mv2 = sess.run(tf.random_uniform(shape=[2,2], dtype=tf.float32))\n",
    "    result = sess.run(product, feed_dict={matrix1:mv1, matrix2:mv2})\n",
    "    print (mv1)\n",
    "    print (mv2)\n",
    "    print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100  loss :  0.0257014  gt :  [0 0 0 1]  predict :  [0 0 0 1]\n",
      "step 200  loss :  0.0103153  gt :  [0 0 0 1]  predict :  [0 0 0 1]\n",
      "step 300  loss :  0.00582025  gt :  [0 0 0 1]  predict :  [0 0 0 1]\n",
      "step 400  loss :  0.00382112  gt :  [0 0 0 1]  predict :  [0 0 0 1]\n",
      "step 500  loss :  0.00273462  gt :  [0 0 0 1]  predict :  [0 0 0 1]\n",
      "step 600  loss :  0.00206929  gt :  [0 0 0 1]  predict :  [0 0 0 1]\n",
      "step 700  loss :  0.00162808  gt :  [0 0 0 1]  predict :  [0 0 0 1]\n",
      "step 800  loss :  0.00131831  gt :  [0 0 0 1]  predict :  [0 0 0 1]\n",
      "step 900  loss :  0.00109132  gt :  [0 0 0 1]  predict :  [0 0 0 1]\n",
      "step 1000  loss :  0.000919332  gt :  [0 0 0 1]  predict :  [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "and_x = np.array([[0,0], [0,1], [1,0],[1,1]])\n",
    "and_y = np.array([0,0,0,1])\n",
    "or_y = np.array([0,1,1,1])\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, 2])\n",
    "label = tf.placeholder(tf.int64, [None])\n",
    "w  = tf.Variable(tf.random_uniform([2,2]))\n",
    "b = tf.Variable(tf.random_uniform([2]))\n",
    "\n",
    "logit = tf.matmul(inputs, w)+b\n",
    "pred_op = tf.nn.softmax(logit)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
    "#opt = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_op)\n",
    "\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1000):\n",
    "        _, loss = sess.run([opt, loss_op], feed_dict={inputs: and_x, label:and_y})\n",
    "        if (step +1) % 100 == 0:\n",
    "            pred = sess.run(pred_op,  feed_dict={inputs: and_x, label:and_y})\n",
    "            print (\"step\", step+1, \" loss : \", loss, \" gt : \", and_y, \" predict : \", np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000  loss :  0.686096  gt :  [1 0 0 1]  predict :  [1 1 0 0]\n",
      "step 2000  loss :  0.581726  gt :  [1 0 0 1]  predict :  [1 0 0 0]\n",
      "step 3000  loss :  0.233252  gt :  [1 0 0 1]  predict :  [1 0 0 1]\n",
      "step 4000  loss :  0.0605868  gt :  [1 0 0 1]  predict :  [1 0 0 1]\n",
      "step 5000  loss :  0.0304698  gt :  [1 0 0 1]  predict :  [1 0 0 1]\n",
      "step 6000  loss :  0.0198136  gt :  [1 0 0 1]  predict :  [1 0 0 1]\n",
      "step 7000  loss :  0.0145339  gt :  [1 0 0 1]  predict :  [1 0 0 1]\n",
      "step 8000  loss :  0.0114199  gt :  [1 0 0 1]  predict :  [1 0 0 1]\n",
      "step 9000  loss :  0.00937839  gt :  [1 0 0 1]  predict :  [1 0 0 1]\n",
      "step 10000  loss :  0.00794195  gt :  [1 0 0 1]  predict :  [1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "xor_y = np.array([1,0,0,1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2,2]))\n",
    "W2 = tf.Variable(tf.random_uniform([2,2]))\n",
    "b1 = tf.Variable(tf.zeros([2]))\n",
    "b2 = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "layer1 = tf.matmul(inputs, W1)+b1\n",
    "layer1 = tf.sigmoid(layer1)\n",
    "logit = tf.matmul(layer1, W2)+b2\n",
    "pred_op = tf.nn.softmax(logit)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = label, logits = logit))\n",
    "#opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
    "\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10000):\n",
    "        _, loss = sess.run([opt, loss_op], feed_dict={inputs: and_x, label:xor_y})\n",
    "        if (step +1) % 1000 == 0:\n",
    "            pred = sess.run(pred_op,  feed_dict={inputs: and_x, label:xor_y})\n",
    "            print (\"step\", step+1, \" loss : \", loss, \" gt : \", xor_y, \" predict : \", np.argmax(pred, axis=1))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bye bye\n"
     ]
    }
   ],
   "source": [
    "print(\"bye bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
